{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the exploratory data analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>passanger</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>coupon</th>\n",
       "      <th>expiration</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>CoffeeHouse</th>\n",
       "      <th>CarryAway</th>\n",
       "      <th>RestaurantLessThan20</th>\n",
       "      <th>Restaurant20To50</th>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>direction_opp</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>55</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Restaurant(&lt;20)</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Carry out &amp; Take away</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       destination  passanger weather  temperature  time  \\\n",
       "0  No Urgent Place      Alone   Sunny           55   2PM   \n",
       "1  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "2  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "3  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "4  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "\n",
       "                  coupon expiration  gender age      maritalStatus  ...  \\\n",
       "0        Restaurant(<20)         1d  Female  21  Unmarried partner  ...   \n",
       "1           Coffee House         2h  Female  21  Unmarried partner  ...   \n",
       "2  Carry out & Take away         2h  Female  21  Unmarried partner  ...   \n",
       "3           Coffee House         2h  Female  21  Unmarried partner  ...   \n",
       "4           Coffee House         1d  Female  21  Unmarried partner  ...   \n",
       "\n",
       "   CoffeeHouse CarryAway RestaurantLessThan20 Restaurant20To50  \\\n",
       "0        never       NaN                  4~8              1~3   \n",
       "1        never       NaN                  4~8              1~3   \n",
       "2        never       NaN                  4~8              1~3   \n",
       "3        never       NaN                  4~8              1~3   \n",
       "4        never       NaN                  4~8              1~3   \n",
       "\n",
       "  toCoupon_GEQ5min toCoupon_GEQ15min toCoupon_GEQ25min direction_same  \\\n",
       "0                1                 0                 0              0   \n",
       "1                1                 0                 0              0   \n",
       "2                1                 1                 0              0   \n",
       "3                1                 1                 0              0   \n",
       "4                1                 1                 0              0   \n",
       "\n",
       "  direction_opp  Y  \n",
       "0             1  1  \n",
       "1             1  0  \n",
       "2             1  1  \n",
       "3             1  0  \n",
       "4             1  0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the dataset\n",
    "\n",
    "df = pd.read_csv('/home/caria/MEDM/Project 1/in-vehicle-coupon-recommendation.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributing to the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('in-vehicle-coupon-recommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show index of duplicates\n",
    "df_duplicate_analisys = df[df.duplicated(keep=False)]\n",
    "\n",
    "def remove_dup(df: pd.DataFrame):\n",
    "    # Now remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value mapping\n",
    "\n",
    "def value_mapping(df: pd.DataFrame):\n",
    "    frequency_map = {'never': 0,'less1': 1,'1~3': 2,'4~8': 3,'gt8': 4}\n",
    "    age_map = {'below21': 0,'21': 1,'26': 2,'31': 3,'36': 4,'41': 5,'46': 6,'50plus': 7}\n",
    "    income_map = {'Less than $12500': 0,'$12500 - $24999': 1,'$25000 - $37499': 2,'$37500 - $49999': 3,\n",
    "    '$50000 - $62499': 4,'$62500 - $74999': 5,'$75000 - $87499': 6,'$87500 - $99999': 7,'$100000 or More': 8}\n",
    "    temperature_map = {30: 0,55: 1,80: 2}\n",
    "\n",
    "    # CoffeeHouse, CarryAway, RestaurantLessThan20, Restaurant20To50, Bar\n",
    "    df['CoffeeHouse'] = df['CoffeeHouse'].map(frequency_map)\n",
    "    df['CarryAway'] = df['CarryAway'].map(frequency_map)\n",
    "    df['RestaurantLessThan20'] = df['RestaurantLessThan20'].map(frequency_map)\n",
    "    df['Restaurant20To50'] = df['Restaurant20To50'].map(frequency_map)\n",
    "    df['Bar'] = df['Bar'].map(frequency_map)\n",
    "\n",
    "    #age\n",
    "    df['age'] = df['age'].map(age_map)\n",
    "\n",
    "    #income \n",
    "    df['income'] = df['income'].map(income_map)\n",
    "\n",
    "    #temperature\n",
    "    df['temperature'] = df['temperature'].map(temperature_map)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "\n",
    "def drop_columns(df: pd.DataFrame):\n",
    "    df = df.drop(columns=['car'])\n",
    "    #df = df.drop(columns=['toCoupon_GEQ5min'])\n",
    "    df = df.drop(columns=['direction_opp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine toCoupon_GEQ5minâ€™, toCoupon_GEQ15minâ€™ and â€˜toCoupon_GEQ25minâ€™ into one column 0, 1, 2 values\n",
    "\n",
    "#0: driving distance is less than or equal to 15 min\n",
    "#1: driving distance is greater than 15 min and less than or equal to 25 min\n",
    "#2: driving distance is greater than 25 min\n",
    "\n",
    "def combine_distance_columns(df):\n",
    "    \"\"\"\n",
    "    Combine 'toCoupon_GEQ5min', 'toCoupon_GEQ15min', and 'toCoupon_GEQ25min' \n",
    "    columns into a single column 'to_coupon'.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    - df (pd.DataFrame): The modified dataframe with the 'to_coupon' column\n",
    "    \"\"\"\n",
    "    \n",
    "    def assign_to_coupon(row):\n",
    "        if row['toCoupon_GEQ25min'] == 1:\n",
    "            return 2\n",
    "        elif row['toCoupon_GEQ15min'] == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # add the new column at penultimate position (before 'Y')\n",
    "    df.insert(len(df.columns) - 1, 'to_coupon', np.nan)\n",
    "    df['to_coupon'] = df.apply(assign_to_coupon, axis=1)\n",
    "\n",
    "    # Drop the original columns\n",
    "    df.drop(['toCoupon_GEQ5min', 'toCoupon_GEQ15min', 'toCoupon_GEQ25min'], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df.copy()\n",
    "\n",
    "df_test1 = remove_dup(df_test1)\n",
    "df_test1 = value_mapping(df_test1)\n",
    "df_test1 = drop_columns(df_test1)\n",
    "df_test1 = combine_distance_columns(df_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age vs Marital Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53298/3257595495.py:25: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/tmp/ipykernel_53298/3257595495.py:40: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/tmp/ipykernel_53298/3257595495.py:57: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# analyzing age with the help of marital status\n",
    "\n",
    "# defining 'age' categories order for visualization\n",
    "custom_order_Age = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# defining 'maritalStatus' categories order for visualization\n",
    "custom_order_MS = ['Single','Unmarried partner','Married partner','Divorced','Widowed']\n",
    "\n",
    "# defining the x-axis legend\n",
    "x_axis = ['below21', '21', '26', '31', '36', '41', '46', '50plus']\n",
    "\n",
    "# pivoting the data to get counts of each combination\n",
    "pivot_df = df_test1.groupby(['age', 'maritalStatus']).size().unstack().fillna(0)\n",
    "\n",
    "# ordering the data based on the custom orders\n",
    "pivot_df = pivot_df.reindex(custom_order_Age)[custom_order_MS]\n",
    "\n",
    "# plotting grouped bar plot\n",
    "pivot_df.plot(kind='bar', figsize=(12, 7), stacked=False)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(custom_order_Age, x_axis)\n",
    "plt.title('Age vs Marital Status')\n",
    "plt.legend(title='Marital Status')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "####################\n",
    "\n",
    "# redoing this, but to analyze the percentage of each marital status per age group instead of raw counts\n",
    "pivot_df = df_test1.groupby(['age', 'maritalStatus']).size().unstack().fillna(0)\n",
    "pivot_df = pivot_df.reindex(custom_order_Age)[custom_order_MS]\n",
    "pivot_df = pivot_df.apply(lambda x: x/x.sum(), axis=1)\n",
    "pivot_df.plot(kind='bar', figsize=(12, 7), stacked=True)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks(custom_order_Age, x_axis)\n",
    "plt.title('Age vs Marital Status')\n",
    "plt.legend(title='Marital Status')\n",
    "plt.show()\n",
    "\n",
    "# now, we create the new taxonomized variable 'tax_age'\n",
    "# along the rules:\n",
    "# 0: below 21         (0)                (young)\n",
    "# 1: 21, 26           (1,2)              (young-adult)\n",
    "# 2: 31, 36, 41, 46   (3,4,5,6)          (adult)\n",
    "# 3: 50plus           (7)                (senior)\n",
    "\n",
    "df_test1['tax_age'] = df_test1['age'].apply(lambda x: 0 if x == 0 else (1 if x in [1, 2] else (2 if x in [3, 4, 5, 6] else 3)))\n",
    "\n",
    "# visualizing its distribution\n",
    "sns.countplot(x='tax_age', data=df_test1)\n",
    "plt.xlabel('tax_age')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1, 2, 3], ['young', 'young-adult', 'adult', 'senior'])\n",
    "plt.title('Distribution of taxonomized variable tax_age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['destination', 'passanger', 'weather', 'temperature', 'time', 'coupon',\n",
      "       'expiration', 'gender', 'age', 'maritalStatus', 'has_children',\n",
      "       'education', 'occupation', 'income', 'Bar', 'CoffeeHouse', 'CarryAway',\n",
      "       'RestaurantLessThan20', 'Restaurant20To50', 'direction_same',\n",
      "       'to_coupon', 'Y', 'tax_age'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "New dataset has 23 variables. \n",
      "Original dataset has 26 variables.\n"
     ]
    }
   ],
   "source": [
    "# checking the new dataset variables\n",
    "print(df_test1.columns)\n",
    "print('\\n')\n",
    "print('New dataset has', len(df_test1.columns), 'variables. \\nOriginal dataset has', len(df.columns), 'variables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupon total frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'never': 0,'less1': 1,'1~3': 2,'4~8': 3,'gt8': 4}\n",
    "\n",
    "\n",
    "# summing all this up\n",
    "def create_coupon_freq_total(number_used_for_gt8, df):\n",
    "    # first, we need to encode the 5 coupon variables: 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50', 'Bar'\n",
    "    # using the mean of each interval as the value to be encoded (what about for gt8?)\n",
    "\n",
    "    coupon_names = ['CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50', 'Bar']\n",
    "    for coupon_name in coupon_names:\n",
    "        df['mean_' + coupon_name] = df[coupon_name].apply(lambda x: 0 if x == 0 else (1 if x == 1 else (2 if x == 2 else (6 if x == 3 else number_used_for_gt8))))\n",
    "\n",
    "    # creating a new variable called coupon_freq_total which is the sum of all the coupon frequency variables\n",
    "    coupon_freq_total = df['mean_CoffeeHouse'] + df['mean_CarryAway'] + df['mean_RestaurantLessThan20'] + df['mean_Restaurant20To50'] + df['mean_Bar']\n",
    "    return coupon_freq_total\n",
    "\n",
    "\n",
    "# creating a new variable called coupon_freq_total which is the sum of all the coupon frequency variables\n",
    "number_used_for_gt8 = 50\n",
    "df_test1['coupon_freq_total'] = create_coupon_freq_total(number_used_for_gt8, df_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53298/631001150.py:11: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# checking the new variable coupon_freq_total\n",
    "\n",
    "# value counts\n",
    "#print(df_test1['coupon_freq_total'].value_counts())\n",
    "# bar plot for bar distribution\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.countplot(x='coupon_freq_total', data=df_test1)\n",
    "plt.xlabel('coupon_freq_total')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of coupon_freq_total')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coupon_freq_total has 0 \"0s\".\n"
     ]
    }
   ],
   "source": [
    "# does coupon_freq_total have 0s?\n",
    "print('coupon_freq_total has', len(df_test1[df_test1['coupon_freq_total'] == 0]), '\"0s\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use this new variable to create the one we actually want: the importance of the given coupon for the given user. We will call this variable `coupon_importance`. \n",
    "\n",
    "Comes from dividing the coupon frequency by the total frequency of the user. E.g. if coupon = 'Bar', then coupon_importance = Bar_frequency / coupon_total_frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized computation of coupon_importance\n",
    "def compute_importance(row):\n",
    "\n",
    "    # Mapping coupon to respective frequency columns\n",
    "    coupon_to_freq_mapping = {\n",
    "        'Coffee House': 'mean_CoffeeHouse',\n",
    "        'Carry out & Take away': 'mean_CarryAway',\n",
    "        'Restaurant(<20)': 'mean_RestaurantLessThan20',\n",
    "        'Restaurant(20-50)': 'mean_Restaurant20To50',\n",
    "        'Bar': 'mean_Bar'\n",
    "    }\n",
    "\n",
    "    given_coupon = coupon_to_freq_mapping[row['coupon']]\n",
    "    total_freq = row['coupon_freq_total']\n",
    "    return row[given_coupon] / total_freq if total_freq else 0\n",
    "\n",
    "df_test1['coupon_importance'] = df_test1.apply(compute_importance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53298/347941370.py:14: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# visualizing new variable coupon_importance distribution\n",
    "\n",
    "# determining unique values and the number of bins\n",
    "bins = df_test1['coupon_importance'].nunique()\n",
    "values, edges = np.histogram(df_test1['coupon_importance'], bins=bins)\n",
    "\n",
    "colors = sns.color_palette(\"crest\", bins)\n",
    "plt.figure(figsize=(12, 7))\n",
    "for i in range(bins):\n",
    "    plt.bar(edges[i], values[i], width=edges[i+1]-edges[i], color=colors[i])\n",
    "plt.xlabel('coupon_importance')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of coupon_importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53298/3859381300.py:47: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# creating a function to plot the percentage of each category of a feature vs the target variable\n",
    "def feature_vs_target(df, feature, target, returnQ = False, plotQ = True):\n",
    "    \"\"\"\n",
    "    Plots a bar plot of the percentage of each category of the feature vs the target variable.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input dataframe\n",
    "    - feature (str): The feature column name\n",
    "    - target (str): The target column name\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculating counts for each category\n",
    "    grouped = df.groupby([feature, target]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Calculating percentages\n",
    "    grouped_percentage = grouped.divide(grouped.sum(axis=1), axis=0) * 100\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    if returnQ == True:\n",
    "        return grouped_percentage\n",
    "    \n",
    "    if plotQ == True:\n",
    "        # Plotting\n",
    "        ax = grouped_percentage.plot(kind='bar', stacked=True, figsize=(12,7))\n",
    "        plt.title(feature + ' vs ' + target)\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Percentage')\n",
    "        plt.yticks([])  # Hide yticks\n",
    "\n",
    "        # Display percentages on the bars\n",
    "        for index, rect in enumerate(ax.patches):\n",
    "            y_value = rect.get_height()\n",
    "            x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "            # Choose the y-value based on the height of the bar segment\n",
    "            vertical_position = rect.get_y() + y_value / 2\n",
    "\n",
    "            label = \"{:.1f}%\".format(y_value)\n",
    "            ax.annotate(label, (x_value, vertical_position), xytext=(0, 0),\n",
    "                        textcoords=\"offset points\", ha='center', va='center', color='white', weight='bold')        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# binning coupon_importance\n",
    "n_bins = 10\n",
    "bins = np.arange(0, 1+1/n_bins, 1/n_bins)\n",
    "labels = [str(round(float(bins[i]), 3)) + '-' + str(round(float(bins[i+1]), 3)) for i in range(n_bins)]\n",
    "\n",
    "\n",
    "\n",
    "df_test1['coupon_importance_bins'] = pd.cut(df_test1['coupon_importance'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# plotting coupon_importance_bins vs Y\n",
    "feature_vs_target(df_test1, 'coupon_importance_bins', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for a nice enough value for number_used_for_gt8, by looking to order P(Y=1 | coupon_importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnumber_used_for_gt8 = 9\\nvalues_that_work = []\\nwhile number_used_for_gt8 in range(9,100):\\n\\n    df_test1['coupon_freq_total'] = create_coupon_freq_total(number_used_for_gt8, df_test1)\\n    df_test1['coupon_importance'] = df_test1.apply(compute_importance, axis=1)\\n    # binning coupon_importance\\n    n_bins = 5\\n    bins = np.arange(0, 1+1/n_bins, 1/n_bins)\\n    labels = [str(round(float(bins[i]), 3)) + '-' + str(round(float(bins[i+1]), 3)) for i in range(n_bins)]\\n    df_test1['coupon_importance_bins'] = pd.cut(df_test1['coupon_importance'], bins=bins, labels=labels, right=False)\\n    # plotting coupon_importance_bins vs Y\\n    prob_data = feature_vs_target(df_test1, 'coupon_importance_bins', 'Y', returnQ=True, plotQ=False)\\n\\n    # extracting only the Y=1 probabilities\\n    prob_data = prob_data[1]\\n\\n    # checking if these probabilities are in ascending order\\n    if prob_data.is_monotonic_increasing:\\n        values_that_work.append(number_used_for_gt8)\\n\\n    # printing at each 100th iteration\\n    if number_used_for_gt8 % 25 == 0:\\n        print('number_used_for_gt8 =', number_used_for_gt8, 'examined.')\\n    \\n    number_used_for_gt8 += 1\\n    \\n\\nprint('Values that work:', values_that_work)\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "number_used_for_gt8 = 9\n",
    "values_that_work = []\n",
    "while number_used_for_gt8 in range(9,100):\n",
    "\n",
    "    df_test1['coupon_freq_total'] = create_coupon_freq_total(number_used_for_gt8, df_test1)\n",
    "    df_test1['coupon_importance'] = df_test1.apply(compute_importance, axis=1)\n",
    "    # binning coupon_importance\n",
    "    n_bins = 5\n",
    "    bins = np.arange(0, 1+1/n_bins, 1/n_bins)\n",
    "    labels = [str(round(float(bins[i]), 3)) + '-' + str(round(float(bins[i+1]), 3)) for i in range(n_bins)]\n",
    "    df_test1['coupon_importance_bins'] = pd.cut(df_test1['coupon_importance'], bins=bins, labels=labels, right=False)\n",
    "    # plotting coupon_importance_bins vs Y\n",
    "    prob_data = feature_vs_target(df_test1, 'coupon_importance_bins', 'Y', returnQ=True, plotQ=False)\n",
    "\n",
    "    # extracting only the Y=1 probabilities\n",
    "    prob_data = prob_data[1]\n",
    "\n",
    "    # checking if these probabilities are in ascending order\n",
    "    if prob_data.is_monotonic_increasing:\n",
    "        values_that_work.append(number_used_for_gt8)\n",
    "\n",
    "    # printing at each 100th iteration\n",
    "    if number_used_for_gt8 % 25 == 0:\n",
    "        print('number_used_for_gt8 =', number_used_for_gt8, 'examined.')\n",
    "    \n",
    "    number_used_for_gt8 += 1\n",
    "    \n",
    "\n",
    "print('Values that work:', values_that_work)\n",
    "'''\n",
    "\n",
    "# With n_bins = 5\n",
    "# range(9, 100)\n",
    "# Values that work: [16, 17, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the probability of Y=1 in ascending order? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53298/3859381300.py:47: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# testing with number_used_for_gt8 = 16 and n_bins = 5\n",
    "\n",
    "number_used_for_gt8 = 16\n",
    "df_test1['coupon_freq_total'] = create_coupon_freq_total(number_used_for_gt8, df_test1)\n",
    "df_test1['coupon_importance'] = df_test1.apply(compute_importance, axis=1)\n",
    "# binning coupon_importance\n",
    "n_bins = 5\n",
    "bins = np.arange(0, 1+1/n_bins, 1/n_bins)\n",
    "labels = [str(round(float(bins[i]), 3)) + '-' + str(round(float(bins[i+1]), 3)) for i in range(n_bins)]\n",
    "df_test1['coupon_importance_bins'] = pd.cut(df_test1['coupon_importance'], bins=bins, labels=labels, right=False)\n",
    "# plotting coupon_importance_bins vs Y\n",
    "prob_data = feature_vs_target(df_test1, 'coupon_importance_bins', 'Y', returnQ=True)\n",
    "\n",
    "# extracting only the Y=1 probabilities\n",
    "prob_data = prob_data[1]\n",
    "\n",
    "# checking if these probabilities are in ascending order\n",
    "print('Is the probability of Y=1 in ascending order?', prob_data.is_monotonic_increasing)\n",
    "\n",
    "feature_vs_target(df_test1, 'coupon_importance_bins', 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Mutual Information between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.392436107823411\n",
      "0.6365141682948128\n",
      "0.2911031660323687\n"
     ]
    }
   ],
   "source": [
    "def MI_num2num(X, Y):\n",
    "    \"\"\"Compute mutual information of two discrete random variables.\n",
    "    \n",
    "    Args:\n",
    "    - X (array-like): A list or array of samples from the first variable.\n",
    "    - Y (array-like): A list or array of samples from the second variable.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Mutual information (MI) between X and Y.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a 2D histogram of the two input variables\n",
    "    joint_prob, _, _ = np.histogram2d(X, Y, bins=(len(np.unique(X)), len(np.unique(Y))), range=((X.min(), X.max()), (Y.min(), Y.max())), density=True)\n",
    "    \n",
    "    # Marginal probabilities\n",
    "    prob_X = np.sum(joint_prob, axis=1)\n",
    "    prob_Y = np.sum(joint_prob, axis=0)\n",
    "    \n",
    "    # Calculate MI\n",
    "    MI = 0\n",
    "    for i in range(joint_prob.shape[0]):\n",
    "        for j in range(joint_prob.shape[1]):\n",
    "            if joint_prob[i, j] > 0:\n",
    "                MI += joint_prob[i, j] * np.log(joint_prob[i, j] / (prob_X[i] * prob_Y[j]))\n",
    "                \n",
    "    return MI\n",
    "\n",
    "# Example\n",
    "X = np.array([0, 0, 1, 1, 2, 2])\n",
    "Y = np.array([0, 1, 1, 0, 2, 2])\n",
    "print(MI_num2num(X, Y))\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "def MI_cat2cat(cat_var1, cat_var2):\n",
    "    \"\"\"Compute mutual information of two categorical variables.\n",
    "    \n",
    "    Args:\n",
    "    - cat_var1 (array-like): A list or array of samples from the first categorical variable.\n",
    "    - cat_var2 (array-like): A list or array of samples from the second categorical variable.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Mutual information (MI) between the two categorical variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(cat_var1, cat_var2)\n",
    "    \n",
    "    # Calculate joint probabilities\n",
    "    joint_prob = contingency_table.values / len(cat_var1)\n",
    "    \n",
    "    # Marginal probabilities\n",
    "    prob_cat_var1 = np.sum(joint_prob, axis=1)\n",
    "    prob_cat_var2 = np.sum(joint_prob, axis=0)\n",
    "    \n",
    "    # Calculate MI\n",
    "    MI = 0\n",
    "    for i in range(joint_prob.shape[0]):\n",
    "        for j in range(joint_prob.shape[1]):\n",
    "            if joint_prob[i, j] > 0:  # Avoid log(0)\n",
    "                MI += joint_prob[i, j] * np.log(joint_prob[i, j] / (prob_cat_var1[i] * prob_cat_var2[j]))\n",
    "    \n",
    "    return MI\n",
    "\n",
    "# Example\n",
    "cat_var1 = ['A', 'A', 'B', 'B', 'C', 'C']\n",
    "cat_var2 = ['W', 'X', 'X', 'W', 'Z', 'Z']\n",
    "print(MI_cat2cat(cat_var1, cat_var2))\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "def MI_num2cat(num_var, cat_var, bins=10):\n",
    "    \"\"\"Compute mutual information between a numerical and a categorical variable.\n",
    "    \n",
    "    Args:\n",
    "    - num_var (array-like): A list or array of samples from the numerical variable.\n",
    "    - cat_var (array-like): A list or array of samples from the categorical variable.\n",
    "    - bins (int or sequence of scalars): Number of bins for discretizing the numerical variable, or the bin edges.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Mutual information (MI) between the numerical and categorical variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Discretize the numerical variable\n",
    "    binned_num_var = pd.cut(num_var, bins=bins, labels=range(bins))\n",
    "    \n",
    "    # Now, calculate mutual information as if between two categorical variables\n",
    "    return MI_cat2cat(binned_num_var, cat_var)\n",
    "\n",
    "# Example\n",
    "num_var = [0.5, 1.5, 2.5, 2.8, 3.5, 4.5, 5.5, 6.2, 7.0, 8.5]\n",
    "cat_var = ['A', 'B', 'B', 'A', 'C', 'C', 'B', 'A', 'C', 'B']\n",
    "print(MI_num2cat(num_var, cat_var, bins=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['destination', 'passanger', 'weather', 'temperature', 'time', 'coupon',\n",
      "       'expiration', 'gender', 'age', 'maritalStatus', 'has_children',\n",
      "       'education', 'occupation', 'income', 'Bar', 'CoffeeHouse', 'CarryAway',\n",
      "       'RestaurantLessThan20', 'Restaurant20To50', 'direction_same',\n",
      "       'to_coupon', 'Y', 'tax_age', 'mean_CoffeeHouse', 'mean_CarryAway',\n",
      "       'mean_RestaurantLessThan20', 'mean_Restaurant20To50', 'mean_Bar',\n",
      "       'coupon_freq_total', 'coupon_importance', 'coupon_importance_bins'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Categorical variables:\n",
      "Index(['destination', 'passanger', 'weather', 'time', 'coupon', 'expiration',\n",
      "       'gender', 'maritalStatus', 'education', 'occupation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "int64\n",
      "Index(['temperature', 'age', 'has_children', 'income', 'direction_same',\n",
      "       'to_coupon', 'Y', 'tax_age', 'mean_CoffeeHouse', 'mean_CarryAway',\n",
      "       'mean_RestaurantLessThan20', 'mean_Restaurant20To50', 'mean_Bar',\n",
      "       'coupon_freq_total'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "float64\n",
      "Index(['Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20',\n",
      "       'Restaurant20To50', 'coupon_importance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# all variables\n",
    "print(df_test1.columns)\n",
    "print('\\n')\n",
    "# checking which variables are categorical and which are numerical\n",
    "print('Categorical variables:')\n",
    "print(df_test1.select_dtypes(include=['object']).columns)\n",
    "print('\\n')\n",
    "print('int64')\n",
    "print(df_test1.select_dtypes(include=['int64']).columns)\n",
    "print('\\n')\n",
    "print('float64')\n",
    "print(df_test1.select_dtypes(include=['float64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI(age, age) = 2.2103412856521008\n",
      "MI(age, Y) = 0.0025100343099697473\n",
      "MI(maritalStatus, Y) = 0.0018893155625209174\n",
      "MI(coupon_freq_total, Y) = 0.002867488041266098\n"
     ]
    }
   ],
   "source": [
    "# testing on the dataset\n",
    "\n",
    "# MI(age, age) (numerical vs numerical)\n",
    "\n",
    "print('MI(age, age) =', MI_num2num(df_test1['age'], df_test1['age']))\n",
    "\n",
    "# MI(age, Y) (numerical vs categorical)\n",
    "\n",
    "print('MI(age, Y) =', MI_num2cat(df_test1['age'], df_test1['Y']))\n",
    "\n",
    "# MI(maritalStatus, Y) (categorical vs categorical)\n",
    "\n",
    "print('MI(maritalStatus, Y) =', MI_cat2cat(df_test1['maritalStatus'], df_test1['Y']))\n",
    "\n",
    "# MI(coupon_freq_total, Y) (numerical vs categorical)\n",
    "\n",
    "print('MI(coupon_freq_total, Y) =', MI_num2cat(df_test1['coupon_freq_total'], df_test1['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passanger\n",
      "weather\n",
      "temperature\n",
      "time\n",
      "coupon\n",
      "expiration\n",
      "gender\n",
      "age\n",
      "maritalStatus\n",
      "has_children\n",
      "education\n",
      "occupation\n",
      "income\n",
      "Bar\n",
      "CoffeeHouse\n",
      "CarryAway\n",
      "RestaurantLessThan20\n",
      "Restaurant20To50\n",
      "direction_same\n",
      "to_coupon\n",
      "Y\n",
      "tax_age\n",
      "mean_CoffeeHouse\n",
      "mean_CarryAway\n",
      "mean_RestaurantLessThan20\n",
      "mean_Restaurant20To50\n",
      "mean_Bar\n",
      "coupon_freq_total\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (30,) and arg 1 with shape (27,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/caria/MEDM/Statistical_Methods_Data_Mining/1_eda/caria.ipynb Cell 36\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caria/MEDM/Statistical_Methods_Data_Mining/1_eda/caria.ipynb#X63sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# plot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caria/MEDM/Statistical_Methods_Data_Mining/1_eda/caria.ipynb#X63sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m7\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/caria/MEDM/Statistical_Methods_Data_Mining/1_eda/caria.ipynb#X63sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m plt\u001b[39m.\u001b[39mbar(df_test1\u001b[39m.\u001b[39mcolumns[\u001b[39m1\u001b[39m:], mi_values)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caria/MEDM/Statistical_Methods_Data_Mining/1_eda/caria.ipynb#X63sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m plt\u001b[39m.\u001b[39mxticks(rotation\u001b[39m=\u001b[39m\u001b[39m90\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caria/MEDM/Statistical_Methods_Data_Mining/1_eda/caria.ipynb#X63sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mFeatures\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/pyplot.py:2367\u001b[0m, in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2363\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mbar)\n\u001b[1;32m   2364\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbar\u001b[39m(\n\u001b[1;32m   2365\u001b[0m         x, height, width\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, bottom\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, align\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcenter\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2366\u001b[0m         data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2367\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mbar(\n\u001b[1;32m   2368\u001b[0m         x, height, width\u001b[39m=\u001b[39mwidth, bottom\u001b[39m=\u001b[39mbottom, align\u001b[39m=\u001b[39malign,\n\u001b[1;32m   2369\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1422\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1425\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1426\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1427\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_axes.py:2391\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[39mif\u001b[39;00m yerr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2389\u001b[0m         yerr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_yunits)\n\u001b[0;32m-> 2391\u001b[0m x, height, width, y, linewidth, hatch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbroadcast_arrays(\n\u001b[1;32m   2392\u001b[0m     \u001b[39m# Make args iterable too.\u001b[39;00m\n\u001b[1;32m   2393\u001b[0m     np\u001b[39m.\u001b[39matleast_1d(x), height, width, y, linewidth, hatch)\n\u001b[1;32m   2395\u001b[0m \u001b[39m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m \u001b[39mif\u001b[39;00m orientation \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/stride_tricks.py:540\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[0;34m(subok, *args)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39m#                  order='C').itviews\u001b[39;00m\n\u001b[1;32m    538\u001b[0m args \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39marray(_m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, subok\u001b[39m=\u001b[39msubok) \u001b[39mfor\u001b[39;00m _m \u001b[39min\u001b[39;00m args]\n\u001b[0;32m--> 540\u001b[0m shape \u001b[39m=\u001b[39m _broadcast_shape(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    542\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(array\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m shape \u001b[39mfor\u001b[39;00m array \u001b[39min\u001b[39;00m args):\n\u001b[1;32m    543\u001b[0m     \u001b[39m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     \u001b[39mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/stride_tricks.py:422\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39msupplied arrays against each other.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39m# consistently\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbroadcast(\u001b[39m*\u001b[39margs[:\u001b[39m32\u001b[39m])\n\u001b[1;32m    423\u001b[0m \u001b[39m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39mfor\u001b[39;00m pos \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m32\u001b[39m, \u001b[39mlen\u001b[39m(args), \u001b[39m31\u001b[39m):\n\u001b[1;32m    425\u001b[0m     \u001b[39m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[39m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[39m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (30,) and arg 1 with shape (27,)."
     ]
    }
   ],
   "source": [
    "# testing MI functions on the dataset\n",
    "# note: Y is binary\n",
    "\n",
    "# let's plot MI(S, Y) for each feature S\n",
    "mi_values = []\n",
    "# let's disregard coupon_importance_bins\n",
    "for feature in df_test1.columns:\n",
    "    print(feature)\n",
    "    if feature != 'Y' and feature != 'coupon_importance_bins':\n",
    "        # categorical features\n",
    "        if df_test1[feature].dtype == 'object':\n",
    "            mi_values.append(MI_cat2cat(df_test1[feature], df_test1['Y']))\n",
    "        # numerical features (float64)\n",
    "        elif df_test1[feature].dtype == 'float64':\n",
    "            mi_values.append(MI_num2cat(df_test1[feature], df_test1['Y']))\n",
    "        # numerical features (int64)\n",
    "        elif df_test1[feature].dtype == 'int64':\n",
    "            mi_values.append(MI_num2cat(df_test1[feature], df_test1['Y']))\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.bar(df_test1.columns[1:], mi_values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Mutual Information')\n",
    "plt.title('Mutual Information between Y and each feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n# Assuming your target variable column name is 'Y'\\nX = df.drop(columns='Y')\\ny = df['Y']\\n\\n# Compute mutual information scores\\nmi_scores = mutual_info_classif(X, y, discrete_features=True)\\n\\n# Create a DataFrame for MI scores and sort them in descending order\\nmi_df = pd.DataFrame({\\n    'Feature': X.columns,\\n    'MI Score with Target': mi_scores\\n}).sort_values(by='MI Score with Target', ascending=False)\\n\\nprint(mi_df)\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "''' \n",
    "# Assuming your target variable column name is 'Y'\n",
    "X = df.drop(columns='Y')\n",
    "y = df['Y']\n",
    "\n",
    "# Compute mutual information scores\n",
    "mi_scores = mutual_info_classif(X, y, discrete_features=True)\n",
    "\n",
    "# Create a DataFrame for MI scores and sort them in descending order\n",
    "mi_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'MI Score with Target': mi_scores\n",
    "}).sort_values(by='MI Score with Target', ascending=False)\n",
    "\n",
    "print(mi_df)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
